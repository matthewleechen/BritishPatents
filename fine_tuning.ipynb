{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewleechen/digitize_woodcroft_patents/blob/main/fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was designed for training in Google Colab Pro. It uses the Detectron2 library for object detection and instance segmentation from Facebook AI Research (https://github.com/facebookresearch/detectron2)."
      ],
      "metadata": {
        "id": "FV0l0XurJWMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare labelled data and directories**"
      ],
      "metadata": {
        "id": "TBh_Z6RLrL1N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7agvGgfdLFU5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Clone forked layout-model-training repo from Layout-Parser\n",
        "! git clone https://github.com/matthewleechen/layout-model-training\n",
        "\n",
        "# Clone forked cocosplit repo from akarazniewicz\n",
        "! git clone https://github.com/matthewleechen/cocosplit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install all dependencies \n",
        "! cd /content/layout-model-training/ && pip install -r requirements.txt\n",
        "! cd /content/cocosplit/ && pip install -r requirements.txt\n",
        "! pip install torchvision && pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.5#egg=detectron2\""
      ],
      "metadata": {
        "id": "NKSlCj5vQZGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change working directory\n",
        "%cd /content/layout-model-training/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-lDwGJ7NRcf",
        "outputId": "20e65448-f980-430a-9556-b40d2679b367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/layout-model-training\n",
            "/content/layout-model-training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart runtime before proceeding. Then upload the COCO annotations file to the directory `/content/layout-model-training/`."
      ],
      "metadata": {
        "id": "EzAEbI3FOXng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file = \"annotations.zip\"\n",
        "\n",
        "# Create data folder\n",
        "output_folder = \"data\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Extract the contents of the annotations file to the data folder\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    for member in zip_ref.namelist():\n",
        "        if not member.startswith('._'):\n",
        "            zip_ref.extract(member, output_folder)\n"
      ],
      "metadata": {
        "id": "yKrh0OxiToNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create outputs folder\n",
        "! mkdir /content/layout-model-training/outputs/"
      ],
      "metadata": {
        "id": "ONDbHS4n4ndp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The outputs folder will contain evaluation data, checkpoint information and model weights following training."
      ],
      "metadata": {
        "id": "l61johhOUe53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data into training and test sets**"
      ],
      "metadata": {
        "id": "XFApjPaNva4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below allocates 80% of the data to the training set, and 20% to the test set. You can change this via the parameter currently set to 0.8."
      ],
      "metadata": {
        "id": "XffI2lydTv80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data \n",
        "! python /content/cocosplit/cocosplit.py --having-annotations --multi-class -s 0.8 \\\n",
        "/content/layout-model-training/data/new_results.json /content/layout-model-training/data/train.json \\\n",
        "/content/layout-model-training/data/test.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMlVNVmUuw7K",
        "outputId": "ead6059e-e3fc-47c0-fe25-68f069769a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 9016 entries in /content/layout-model-training/data/train.json and 2254 in /content/layout-model-training/data/test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Detectron2 vision models**"
      ],
      "metadata": {
        "id": "aJh1-_b8vgo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Continue training from last checkpoint***\n",
        "\n",
        "Upload the `last_checkpoint` file and the model weights file (`model_{number of iterations}.pth`) to the outputs folder.\n",
        "\n",
        "***Start training from default pre-trained model weights***\n",
        "\n",
        "Ensure the outputs folder is empty. \n",
        "\n",
        "***Evaluation only***\n",
        "\n",
        "Pass the `--eval-only MODEL.WEIGHTS /content/layout-model-training/outputs/last_checkpoint` argument to the `train_annotations.sh` file.\n"
      ],
      "metadata": {
        "id": "wki93w1F6Oyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The default model in `train_annotations.sh` is Fast-RCNN with a ResNet-50 backbone and a feature pyramid network (config file: `fast_rcnn_R_50_FPN_3x.yaml`). There is also Mask-RCNN with the same backbone and feature pyramid network (config file: `mask_rcnn_R_50_FPN_3x.yaml `). Mask-RCNN is an instance segmentation model and so you will need a COCO dataset with segmentation masks, or else an attribute error will be returned. You can try other models from the Detectron2 library (https://github.com/facebookresearch/detectron2/tree/main/configs).\n",
        "\n",
        "Hyperparameters can be adjusted from the configuration files directly. If training diverges, you will likely need to reduce the base learning rate (`BASE_LR` in the config file). "
      ],
      "metadata": {
        "id": "sassKe-lW5Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "! bash /content/layout-model-training/scripts/train_annotations.sh"
      ],
      "metadata": {
        "id": "eThyeWoS1Tg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you stop training, you **must** save the contents of the outputs folder to your local directory (Colab deletes local files once the runtime is deleted)."
      ],
      "metadata": {
        "id": "P7JktN796hPg"
      }
    }
  ]
}